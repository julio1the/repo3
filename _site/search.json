[
  {
    "objectID": "assignment03-juliovargas.html",
    "href": "assignment03-juliovargas.html",
    "title": "Assignment 03",
    "section": "",
    "text": "from pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import col, split, explode, regexp_replace, transform, when\nfrom pyspark.sql.functions import col, monotonically_increasing_id\nfrom pyspark.sql.types import StructType  # to/from JSON\n\nimport json\nimport re\nimport numpy as np\nimport pandas as pd\n\nimport plotly.express as px\nimport plotly.io as pio\nimport plotly.graph_objects as go\n\n\nnp.random.seed(30)  # set a fixed seed for reproducibility\npio.renderers.default = \"vscode+notebook\"   #\n# Initialize Spark Session\nspark = SparkSession.builder.appName(\"JobPostingsAnalysis\").getOrCreate()\n# Load schema from JSON file\nwith open(\"data/schema_lightcast.json\") as f:\n    schema = StructType.fromJson(json.load(f))\n\n# Load Data\ndf = (spark.read\n      .option(\"header\", \"true\")\n      .option(\"inferSchema\", \"false\")\n      .schema(schema)              # saved schema\n      .option(\"multiLine\", \"true\")\n      .option(\"escape\", \"\\\"\")\n      .csv(\"data/lightcast_job_postings.csv\")\n      .limit(5000))\n\ndf.createOrReplaceTempView(\"job_postings\")\n# Show Schema and Sample Data\n#df.printSchema()  \ndf.show(5)\n\n+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\n|                  ID|LAST_UPDATED_DATE|LAST_UPDATED_TIMESTAMP|DUPLICATES|  POSTED|  EXPIRED|DURATION|        SOURCE_TYPES|             SOURCES|                 URL|ACTIVE_URLS|ACTIVE_SOURCES_INFO|           TITLE_RAW|                BODY|MODELED_EXPIRED|MODELED_DURATION| COMPANY|        COMPANY_NAME|COMPANY_RAW|COMPANY_IS_STAFFING|EDUCATION_LEVELS|EDUCATION_LEVELS_NAME|MIN_EDULEVELS| MIN_EDULEVELS_NAME|MAX_EDULEVELS|MAX_EDULEVELS_NAME|EMPLOYMENT_TYPE|EMPLOYMENT_TYPE_NAME|MIN_YEARS_EXPERIENCE|MAX_YEARS_EXPERIENCE|IS_INTERNSHIP|SALARY|REMOTE_TYPE|REMOTE_TYPE_NAME|ORIGINAL_PAY_PERIOD|SALARY_TO|SALARY_FROM|            LOCATION|                CITY|    CITY_NAME|COUNTY|   COUNTY_NAME|  MSA|            MSA_NAME|STATE|STATE_NAME|COUNTY_OUTGOING|COUNTY_NAME_OUTGOING|COUNTY_INCOMING|COUNTY_NAME_INCOMING|MSA_OUTGOING|   MSA_NAME_OUTGOING|MSA_INCOMING|   MSA_NAME_INCOMING|NAICS2|         NAICS2_NAME|NAICS3|         NAICS3_NAME|NAICS4|         NAICS4_NAME|NAICS5|         NAICS5_NAME|NAICS6|         NAICS6_NAME|             TITLE|         TITLE_NAME|         TITLE_CLEAN|              SKILLS|         SKILLS_NAME|  SPECIALIZED_SKILLS|SPECIALIZED_SKILLS_NAME|      CERTIFICATIONS| CERTIFICATIONS_NAME|       COMMON_SKILLS|  COMMON_SKILLS_NAME|     SOFTWARE_SKILLS|SOFTWARE_SKILLS_NAME|      ONET|           ONET_NAME| ONET_2019|      ONET_2019_NAME|                CIP6|           CIP6_NAME|                CIP4|           CIP4_NAME|                CIP2|           CIP2_NAME|SOC_2021_2|     SOC_2021_2_NAME|SOC_2021_3|     SOC_2021_3_NAME|SOC_2021_4|SOC_2021_4_NAME|SOC_2021_5|SOC_2021_5_NAME|LOT_CAREER_AREA|LOT_CAREER_AREA_NAME|LOT_OCCUPATION| LOT_OCCUPATION_NAME|LOT_SPECIALIZED_OCCUPATION|LOT_SPECIALIZED_OCCUPATION_NAME|LOT_OCCUPATION_GROUP|LOT_OCCUPATION_GROUP_NAME|LOT_V6_SPECIALIZED_OCCUPATION|LOT_V6_SPECIALIZED_OCCUPATION_NAME|LOT_V6_OCCUPATION|LOT_V6_OCCUPATION_NAME|LOT_V6_OCCUPATION_GROUP|LOT_V6_OCCUPATION_GROUP_NAME|LOT_V6_CAREER_AREA|LOT_V6_CAREER_AREA_NAME|  SOC_2|          SOC_2_NAME|  SOC_3|          SOC_3_NAME|  SOC_4|     SOC_4_NAME|  SOC_5|     SOC_5_NAME|LIGHTCAST_SECTORS|LIGHTCAST_SECTORS_NAME|NAICS_2022_2|   NAICS_2022_2_NAME|NAICS_2022_3|   NAICS_2022_3_NAME|NAICS_2022_4|   NAICS_2022_4_NAME|NAICS_2022_5|   NAICS_2022_5_NAME|NAICS_2022_6|   NAICS_2022_6_NAME|\n+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\n|1f57d95acf4dc67ed...|         9/6/2024|  2024-09-06 20:32:...|         0|6/2/2024| 6/8/2024|       6|   [\\n  \"Company\"\\n]|[\\n  \"brassring.c...|[\\n  \"https://sjo...|         []|               NULL|Enterprise Analys...|31-May-2024\\n\\nEn...|       6/8/2024|               6|  894731|          Murphy USA| Murphy USA|              false|       [\\n  2\\n]| [\\n  \"Bachelor's ...|            2|  Bachelor's degree|         NULL|              NULL|              1|Full-time (&gt; 32 h...|                   2|                   2|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 33.20...|RWwgRG9yYWRvLCBBUg==|El Dorado, AR|  5139|     Union, AR|20980|       El Dorado, AR|    5|  Arkansas|           5139|           Union, AR|           5139|           Union, AR|       20980|       El Dorado, AR|       20980|       El Dorado, AR|    44|        Retail Trade|   441|Motor Vehicle and...|  4413|Automotive Parts,...| 44133|Automotive Parts ...|441330|Automotive Parts ...|ET29C073C03D1F86B4|Enterprise Analysts|enterprise analys...|[\\n  \"KS126DB6T06...|[\\n  \"Merchandisi...|[\\n  \"KS126DB6T06...|   [\\n  \"Merchandisi...|                  []|                  []|[\\n  \"KS126706DPF...|[\\n  \"Mathematics...|[\\n  \"KS440W865GC...|[\\n  \"SQL (Progra...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|[\\n  \"45.0601\",\\n...|[\\n  \"Economics, ...|[\\n  \"45.06\",\\n  ...|[\\n  \"Economics\",...|[\\n  \"45\",\\n  \"27...|[\\n  \"Social Scie...|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101011|           General ERP Analy...|                2310|     Business Intellig...|                     23101011|              General ERP Analy...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|        [\\n  7\\n]|  [\\n  \"Artificial ...|          44|        Retail Trade|         441|Motor Vehicle and...|        4413|Automotive Parts,...|       44133|Automotive Parts ...|      441330|Automotive Parts ...|\n|0cb072af26757b6c4...|         8/2/2024|  2024-08-02 17:08:...|         0|6/2/2024| 8/1/2024|    NULL| [\\n  \"Job Board\"\\n]| [\\n  \"maine.gov\"\\n]|[\\n  \"https://job...|         []|               NULL|Oracle Consultant...|Oracle Consultant...|       8/1/2024|            NULL|  133098|Smx Corporation L...|        SMX|               true|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              1|Full-time (&gt; 32 h...|                   3|                   3|        false|  NULL|          1|          Remote|               NULL|     NULL|       NULL|{\\n  \"lat\": 44.31...|    QXVndXN0YSwgTUU=|  Augusta, ME| 23011|  Kennebec, ME|12300|Augusta-Watervill...|   23|     Maine|          23011|        Kennebec, ME|          23011|        Kennebec, ME|       12300|Augusta-Watervill...|       12300|Augusta-Watervill...|    56|Administrative an...|   561|Administrative an...|  5613| Employment Services| 56132|Temporary Help Se...|561320|Temporary Help Se...|ET21DDA63780A7DC09| Oracle Consultants|oracle consultant...|[\\n  \"KS122626T55...|[\\n  \"Procurement...|[\\n  \"KS122626T55...|   [\\n  \"Procurement...|                  []|                  []|                  []|                  []|[\\n  \"BGSBF3F508F...|[\\n  \"Oracle Busi...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101012|           Oracle Consultant...|                2310|     Business Intellig...|                     23101012|              Oracle Consultant...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          56|Administrative an...|         561|Administrative an...|        5613| Employment Services|       56132|Temporary Help Se...|      561320|Temporary Help Se...|\n|85318b12b3331fa49...|         9/6/2024|  2024-09-06 20:32:...|         1|6/2/2024| 7/7/2024|      35| [\\n  \"Job Board\"\\n]|[\\n  \"dejobs.org\"\\n]|[\\n  \"https://dej...|         []|               NULL|        Data Analyst|Taking care of pe...|      6/10/2024|               8|39063746|            Sedgwick|   Sedgwick|              false|       [\\n  2\\n]| [\\n  \"Bachelor's ...|            2|  Bachelor's degree|         NULL|              NULL|              1|Full-time (&gt; 32 h...|                   5|                NULL|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 32.77...|    RGFsbGFzLCBUWA==|   Dallas, TX| 48113|    Dallas, TX|19100|Dallas-Fort Worth...|   48|     Texas|          48113|          Dallas, TX|          48113|          Dallas, TX|       19100|Dallas-Fort Worth...|       19100|Dallas-Fort Worth...|    52|Finance and Insur...|   524|Insurance Carrier...|  5242|Agencies, Brokera...| 52429|Other Insurance R...|524291|    Claims Adjusting|ET3037E0C947A02404|      Data Analysts|        data analyst|[\\n  \"KS1218W78FG...|[\\n  \"Management\"...|[\\n  \"ESF3939CE1F...|   [\\n  \"Exception R...|[\\n  \"KS683TN76T7...|[\\n  \"Security Cl...|[\\n  \"KS1218W78FG...|[\\n  \"Management\"...|[\\n  \"KS126HY6YLT...|[\\n  \"Microsoft O...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231113|Data / Data Minin...|                  23111310|                   Data Analyst|                2311|     Data Analysis and...|                     23111310|                      Data Analyst|           231113|  Data / Data Minin...|                   2311|        Data Analysis and...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          52|Finance and Insur...|         524|Insurance Carrier...|        5242|Agencies, Brokera...|       52429|Other Insurance R...|      524291|    Claims Adjusting|\n|1b5c3941e54a1889e...|         9/6/2024|  2024-09-06 20:32:...|         1|6/2/2024|7/20/2024|      48| [\\n  \"Job Board\"\\n]|[\\n  \"disabledper...|[\\n  \"https://www...|         []|               NULL|Sr. Lead Data Mgm...|About this role:\\...|      6/12/2024|              10|37615159|         Wells Fargo|Wells Fargo|              false|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              1|Full-time (&gt; 32 h...|                   3|                NULL|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 33.44...|    UGhvZW5peCwgQVo=|  Phoenix, AZ|  4013|  Maricopa, AZ|38060|Phoenix-Mesa-Chan...|    4|   Arizona|           4013|        Maricopa, AZ|           4013|        Maricopa, AZ|       38060|Phoenix-Mesa-Chan...|       38060|Phoenix-Mesa-Chan...|    52|Finance and Insur...|   522|Credit Intermedia...|  5221|Depository Credit...| 52211|  Commercial Banking|522110|  Commercial Banking|ET2114E0404BA30075|Management Analysts|sr lead data mgmt...|[\\n  \"KS123QX62QY...|[\\n  \"Exit Strate...|[\\n  \"KS123QX62QY...|   [\\n  \"Exit Strate...|                  []|                  []|[\\n  \"KS7G6NP6R6L...|[\\n  \"Reliability...|[\\n  \"KS4409D76NW...|[\\n  \"SAS (Softwa...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231113|Data / Data Minin...|                  23111310|                   Data Analyst|                2311|     Data Analysis and...|                     23111310|                      Data Analyst|           231113|  Data / Data Minin...|                   2311|        Data Analysis and...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|        [\\n  6\\n]|  [\\n  \"Data Privac...|          52|Finance and Insur...|         522|Credit Intermedia...|        5221|Depository Credit...|       52211|  Commercial Banking|      522110|  Commercial Banking|\n|cb5ca25f02bdf25c1...|        6/19/2024|   2024-06-19 07:00:00|         0|6/2/2024|6/17/2024|      15|[\\n  \"FreeJobBoar...|[\\n  \"craigslist....|[\\n  \"https://mod...|         []|               NULL|Comisiones de $10...|Comisiones de $10...|      6/17/2024|              15|       0|        Unclassified|      LH/GM|              false|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              3|Part-time / full-...|                NULL|                NULL|        false| 92500|          0|          [None]|               year|   150000|      35000|{\\n  \"lat\": 37.63...|    TW9kZXN0bywgQ0E=|  Modesto, CA|  6099|Stanislaus, CA|33700|         Modesto, CA|    6|California|           6099|      Stanislaus, CA|           6099|      Stanislaus, CA|       33700|         Modesto, CA|       33700|         Modesto, CA|    99|Unclassified Indu...|   999|Unclassified Indu...|  9999|Unclassified Indu...| 99999|Unclassified Indu...|999999|Unclassified Indu...|ET0000000000000000|       Unclassified|comisiones de por...|                  []|                  []|                  []|                     []|                  []|                  []|                  []|                  []|                  []|                  []|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101012|           Oracle Consultant...|                2310|     Business Intellig...|                     23101012|              Oracle Consultant...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          99|Unclassified Indu...|         999|Unclassified Indu...|        9999|Unclassified Indu...|       99999|Unclassified Indu...|      999999|Unclassified Indu...|\n+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\nonly showing top 5 rows\n# Histogram of SALARY distribution (cast + filter)\nsalary_df = (\n    df.select(col(\"SALARY\").cast(\"float\"))\n      .filter(col(\"SALARY\").isNotNull() & (col(\"SALARY\") &gt; 0))\n)\n\nfig = px.histogram(\n    salary_df.toPandas(),\n    x=\"SALARY\",\n    nbins=50,\n    title=\"Salary Distribution\"\n)\nfig.update_layout(bargap=0.1)\nfig"
  },
  {
    "objectID": "assignment03_sol.html",
    "href": "assignment03_sol.html",
    "title": "Assignment 03",
    "section": "",
    "text": "Julio Vargas (Boston University)\nSeptember 21, 2025\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import col, split, explode, regexp_replace, transform, when\nfrom pyspark.sql.functions import col, monotonically_increasing_id\nfrom pyspark.sql.types import StructType  # to/from JSON\n\nimport json\nimport re\nimport numpy as np\nimport pandas as pd\n\nimport plotly.express as px\nimport plotly.io as pio\nimport plotly.graph_objects as go\n\n\nnp.random.seed(30)  # set a fixed seed for reproducibility\npio.renderers.default = \"notebook\"\n# Initialize Spark Session\nspark = SparkSession.builder.appName(\"JobPostingsAnalysis\").getOrCreate()\n# Load schema from JSON file\nwith open(\"data/schema_lightcast.json\") as f:\n    schema = StructType.fromJson(json.load(f))\n\n# Load Data\ndf = (spark.read\n      .option(\"header\", \"true\")\n      .option(\"inferSchema\", \"false\")\n      .schema(schema)              # saved schema\n      .option(\"multiLine\", \"true\")\n      .option(\"escape\", \"\\\"\")\n      .csv(\"data/lightcast_job_postings.csv\"))\n# Show Schema and Sample Data\n#df.printSchema()  \n#df.show(5)\n\nWARNING: Using incubator modules: jdk.incubator.vector\nUsing Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n25/09/21 23:31:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n# Histogram of SALARY distribution\nsalary_df = df.filter(col(\"SALARY\").isNotNull() & (col(\"SALARY\") &gt; 0))\nfig = px.histogram(\n    salary_df.toPandas(),\n    x=\"SALARY\",\n    nbins=50,\n    title=\"Salary Distribution\"\n)\n\nfig.update_layout(bargap=0.1)\nfig\n\n25/09/21 23:31:59 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n25/09/21 23:32:12 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)/ 1]\njava.lang.OutOfMemoryError: Java heap space\n    at java.base/java.nio.HeapByteBuffer.&lt;init&gt;(HeapByteBuffer.java:64)\n    at java.base/java.nio.ByteBuffer.allocate(ByteBuffer.java:363)\n    at org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1(SerializerHelper.scala:40)\n    at org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1$adapted(SerializerHelper.scala:40)\n    at org.apache.spark.serializer.SerializerHelper$$$Lambda$3196/0x00007240ccf204b8.apply(Unknown Source)\n    at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)\n    at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)\n    at java.base/java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1862)\n    at java.base/java.io.ObjectOutputStream.write(ObjectOutputStream.java:714)\n    at org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1(Utils.scala:217)\n    at org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1$adapted(Utils.scala:217)\n    at org.apache.spark.util.Utils$$$Lambda$3199/0x00007240ccf21fe0.apply(Unknown Source)\n    at org.apache.spark.util.Utils$.writeByteBufferImpl(Utils.scala:195)\n    at org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:217)\n    at org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2(ChunkedByteBuffer.scala:104)\n    at org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2$adapted(ChunkedByteBuffer.scala:104)\n    at org.apache.spark.util.io.ChunkedByteBuffer$$Lambda$3198/0x00007240ccf21c10.apply(Unknown Source)\n    at scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n    at org.apache.spark.util.io.ChunkedByteBuffer.writeExternal(ChunkedByteBuffer.scala:104)\n    at org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$1(TaskResult.scala:60)\n    at org.apache.spark.scheduler.DirectTaskResult$$Lambda$3205/0x00007240ccf238a0.apply$mcV$sp(Unknown Source)\n    at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n    at org.apache.spark.util.SparkErrorUtils.tryOrIOException(SparkErrorUtils.scala:35)\n    at org.apache.spark.util.SparkErrorUtils.tryOrIOException$(SparkErrorUtils.scala:33)\n    at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:99)\n    at org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:59)\n    at java.base/java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1465)\n    at java.base/java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1436)\n    at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181)\n    at java.base/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350)\n    at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:47)\n    at org.apache.spark.serializer.SerializerHelper$.serializeToChunkedBuffer(SerializerHelper.scala:42)\n25/09/21 23:32:12 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 0.0 in stage 0.0 (TID 0),5,main]\njava.lang.OutOfMemoryError: Java heap space\n    at java.base/java.nio.HeapByteBuffer.&lt;init&gt;(HeapByteBuffer.java:64)\n    at java.base/java.nio.ByteBuffer.allocate(ByteBuffer.java:363)\n    at org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1(SerializerHelper.scala:40)\n    at org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1$adapted(SerializerHelper.scala:40)\n    at org.apache.spark.serializer.SerializerHelper$$$Lambda$3196/0x00007240ccf204b8.apply(Unknown Source)\n    at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)\n    at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)\n    at java.base/java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1862)\n    at java.base/java.io.ObjectOutputStream.write(ObjectOutputStream.java:714)\n    at org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1(Utils.scala:217)\n    at org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1$adapted(Utils.scala:217)\n    at org.apache.spark.util.Utils$$$Lambda$3199/0x00007240ccf21fe0.apply(Unknown Source)\n    at org.apache.spark.util.Utils$.writeByteBufferImpl(Utils.scala:195)\n    at org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:217)\n    at org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2(ChunkedByteBuffer.scala:104)\n    at org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2$adapted(ChunkedByteBuffer.scala:104)\n    at org.apache.spark.util.io.ChunkedByteBuffer$$Lambda$3198/0x00007240ccf21c10.apply(Unknown Source)\n    at scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n    at org.apache.spark.util.io.ChunkedByteBuffer.writeExternal(ChunkedByteBuffer.scala:104)\n    at org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$1(TaskResult.scala:60)\n    at org.apache.spark.scheduler.DirectTaskResult$$Lambda$3205/0x00007240ccf238a0.apply$mcV$sp(Unknown Source)\n    at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n    at org.apache.spark.util.SparkErrorUtils.tryOrIOException(SparkErrorUtils.scala:35)\n    at org.apache.spark.util.SparkErrorUtils.tryOrIOException$(SparkErrorUtils.scala:33)\n    at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:99)\n    at org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:59)\n    at java.base/java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1465)\n    at java.base/java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1436)\n    at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181)\n    at java.base/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350)\n    at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:47)\n    at org.apache.spark.serializer.SerializerHelper$.serializeToChunkedBuffer(SerializerHelper.scala:42)\n25/09/21 23:32:12 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0) (ip-172-31-28-19.ec2.internal executor driver): java.lang.OutOfMemoryError: Java heap space\n    at java.base/java.nio.HeapByteBuffer.&lt;init&gt;(HeapByteBuffer.java:64)\n    at java.base/java.nio.ByteBuffer.allocate(ByteBuffer.java:363)\n    at org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1(SerializerHelper.scala:40)\n    at org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1$adapted(SerializerHelper.scala:40)\n    at org.apache.spark.serializer.SerializerHelper$$$Lambda$3196/0x00007240ccf204b8.apply(Unknown Source)\n    at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)\n    at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)\n    at java.base/java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1862)\n    at java.base/java.io.ObjectOutputStream.write(ObjectOutputStream.java:714)\n    at org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1(Utils.scala:217)\n    at org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1$adapted(Utils.scala:217)\n    at org.apache.spark.util.Utils$$$Lambda$3199/0x00007240ccf21fe0.apply(Unknown Source)\n    at org.apache.spark.util.Utils$.writeByteBufferImpl(Utils.scala:195)\n    at org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:217)\n    at org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2(ChunkedByteBuffer.scala:104)\n    at org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2$adapted(ChunkedByteBuffer.scala:104)\n    at org.apache.spark.util.io.ChunkedByteBuffer$$Lambda$3198/0x00007240ccf21c10.apply(Unknown Source)\n    at scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1324)\n    at org.apache.spark.util.io.ChunkedByteBuffer.writeExternal(ChunkedByteBuffer.scala:104)\n    at org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$1(TaskResult.scala:60)\n    at org.apache.spark.scheduler.DirectTaskResult$$Lambda$3205/0x00007240ccf238a0.apply$mcV$sp(Unknown Source)\n    at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n    at org.apache.spark.util.SparkErrorUtils.tryOrIOException(SparkErrorUtils.scala:35)\n    at org.apache.spark.util.SparkErrorUtils.tryOrIOException$(SparkErrorUtils.scala:33)\n    at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:99)\n    at org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:59)\n    at java.base/java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1465)\n    at java.base/java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1436)\n    at java.base/java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1181)\n    at java.base/java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:350)\n    at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:47)\n    at org.apache.spark.serializer.SerializerHelper$.serializeToChunkedBuffer(SerializerHelper.scala:42)\n\n25/09/21 23:32:12 ERROR TaskSetManager: Task 0 in stage 0.0 failed 1 times; aborting job\n[Stage 0:&gt;                                                          (0 + 0) / 1]\n\n\n\n---------------------------------------------------------------------------\nPy4JJavaError                             Traceback (most recent call last)\n    [... skipping hidden 1 frame]\n\nCell In[2], line 4\n      2 salary_df = df.filter(col(\"SALARY\").isNotNull() & (col(\"SALARY\") &gt; 0))\n      3 fig = px.histogram(\n----&gt; 4     salary_df.toPandas(),\n      5     x=\"SALARY\",\n      6     nbins=50,\n      7     title=\"Salary Distribution\"\n      8 )\n     10 fig.update_layout(bargap=0.1)\n\nFile ~/repo3/.venv/lib/python3.12/site-packages/pyspark/sql/classic/dataframe.py:1792, in DataFrame.toPandas(self)\n   1791 def toPandas(self) -&gt; \"PandasDataFrameLike\":\n-&gt; 1792     return PandasConversionMixin.toPandas(self)\n\nFile ~/repo3/.venv/lib/python3.12/site-packages/pyspark/sql/pandas/conversion.py:197, in PandasConversionMixin.toPandas(self)\n    196 # Below is toPandas without Arrow optimization.\n--&gt; 197 rows = self.collect()\n    198 if len(rows) &gt; 0:\n\nFile ~/repo3/.venv/lib/python3.12/site-packages/pyspark/sql/classic/dataframe.py:443, in DataFrame.collect(self)\n    442 with SCCallSiteSync(self._sc):\n--&gt; 443     sock_info = self._jdf.collectToPython()\n    444 return list(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n\nFile ~/repo3/.venv/lib/python3.12/site-packages/py4j/java_gateway.py:1362, in JavaMember.__call__(self, *args)\n   1361 answer = self.gateway_client.send_command(command)\n-&gt; 1362 return_value = get_return_value(\n   1363     answer, self.gateway_client, self.target_id, self.name)\n   1365 for temp_arg in temp_args:\n\nFile ~/repo3/.venv/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py:282, in capture_sql_exception.&lt;locals&gt;.deco(*a, **kw)\n    281 try:\n--&gt; 282     return f(*a, **kw)\n    283 except Py4JJavaError as e:\n\nFile ~/repo3/.venv/lib/python3.12/site-packages/py4j/protocol.py:327, in get_return_value(answer, gateway_client, target_id, name)\n    326 if answer[1] == REFERENCE_TYPE:\n--&gt; 327     raise Py4JJavaError(\n    328         \"An error occurred while calling {0}{1}{2}.\\n\".\n    329         format(target_id, \".\", name), value)\n    330 else:\n\n&lt;class 'str'&gt;: (&lt;class 'ConnectionRefusedError'&gt;, ConnectionRefusedError(111, 'Connection refused'))\n\nDuring handling of the above exception, another exception occurred:\n\nConnectionRefusedError                    Traceback (most recent call last)\n    [... skipping hidden 1 frame]\n\nFile ~/repo3/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2184, in InteractiveShell.showtraceback(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\n   2181         traceback.print_exc()\n   2182         return None\n-&gt; 2184     self._showtraceback(etype, value, stb)\n   2185 if self.call_pdb:\n   2186     # drop into debugger\n   2187     self.debugger(force=True)\n\nFile ~/repo3/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py:559, in ZMQInteractiveShell._showtraceback(self, etype, evalue, stb)\n    553 sys.stdout.flush()\n    554 sys.stderr.flush()\n    556 exc_content = {\n    557     \"traceback\": stb,\n    558     \"ename\": str(etype.__name__),\n--&gt; 559     \"evalue\": str(evalue),\n    560 }\n    562 dh = self.displayhook\n    563 # Send exception info over pub socket for other clients than the caller\n    564 # to pick up\n\nFile ~/repo3/.venv/lib/python3.12/site-packages/py4j/protocol.py:472, in Py4JJavaError.__str__(self)\n    470 def __str__(self):\n    471     gateway_client = self.java_exception._gateway_client\n--&gt; 472     answer = gateway_client.send_command(self.exception_cmd)\n    473     return_value = get_return_value(answer, gateway_client, None, None)\n    474     # Note: technically this should return a bytestring 'str' rather than\n    475     # unicodes in Python 2; however, it can return unicodes for now.\n    476     # See https://github.com/bartdag/py4j/issues/306 for more details.\n\nFile ~/repo3/.venv/lib/python3.12/site-packages/py4j/java_gateway.py:1036, in GatewayClient.send_command(self, command, retry, binary)\n   1015 def send_command(self, command, retry=True, binary=False):\n   1016     \"\"\"Sends a command to the JVM. This method is not intended to be\n   1017        called directly by Py4J users. It is usually called by\n   1018        :class:`JavaMember` instances.\n   (...)   1034      if `binary` is `True`.\n   1035     \"\"\"\n-&gt; 1036     connection = self._get_connection()\n   1037     try:\n   1038         response = connection.send_command(command)\n\nFile ~/repo3/.venv/lib/python3.12/site-packages/py4j/clientserver.py:284, in JavaClient._get_connection(self)\n    281     pass\n    283 if connection is None or connection.socket is None:\n--&gt; 284     connection = self._create_new_connection()\n    285 return connection\n\nFile ~/repo3/.venv/lib/python3.12/site-packages/py4j/clientserver.py:291, in JavaClient._create_new_connection(self)\n    287 def _create_new_connection(self):\n    288     connection = ClientServerConnection(\n    289         self.java_parameters, self.python_parameters,\n    290         self.gateway_property, self)\n--&gt; 291     connection.connect_to_java_server()\n    292     self.set_thread_connection(connection)\n    293     return connection\n\nFile ~/repo3/.venv/lib/python3.12/site-packages/py4j/clientserver.py:438, in ClientServerConnection.connect_to_java_server(self)\n    435 if self.ssl_context:\n    436     self.socket = self.ssl_context.wrap_socket(\n    437         self.socket, server_hostname=self.java_address)\n--&gt; 438 self.socket.connect((self.java_address, self.java_port))\n    439 self.stream = self.socket.makefile(\"rb\")\n    440 self.is_connected = True\n\nConnectionRefusedError: [Errno 111] Connection refused"
  },
  {
    "objectID": "assignment03_sol.html#salary-distribution-by-industry-and-employment-type",
    "href": "assignment03_sol.html#salary-distribution-by-industry-and-employment-type",
    "title": "Assignment 03",
    "section": "1.1 Salary Distribution by Industry and Employment Type",
    "text": "1.1 Salary Distribution by Industry and Employment Type\n\nCompare salary variations across industries.\n\nFilter the dataset - Remove records where salary is missing or zero.\nAggregate Data - Group by NAICS industry codes (e.g., NAICS2_NAME). - Group by employment type (EMPLOYMENT_TYPE_NAME) and compute salary distribution. - Calculate salary percentiles (25th, 50th, 75th) for each group.\nVisualize results - Create a box plot where: - X-axis = NAICS2_NAME - Y-axis = SALARY_FROM, or SALARY_TO, or SALARY - Group/color = EMPLOYMENT_TYPE_NAME - Customize colors, fonts, and styles.\nExplanation: Write two sentences about what the graph reveals (e.g., median differences across industries and dispersion by employment type)."
  },
  {
    "objectID": "assignment03-juliovargas.html#salary-distribution-by-industry-and-employment-type",
    "href": "assignment03-juliovargas.html#salary-distribution-by-industry-and-employment-type",
    "title": "Assignment 03",
    "section": "1.1 Salary Distribution by Industry and Employment Type",
    "text": "1.1 Salary Distribution by Industry and Employment Type\n\nCompare salary variations across industries.\n\nFilter the dataset - Remove records where salary is missing or zero.\nAggregate Data - Group by NAICS industry codes (e.g., NAICS2_NAME). - Group by employment type (EMPLOYMENT_TYPE_NAME) and compute salary distribution. - Calculate salary percentiles (25th, 50th, 75th) for each group.\nVisualize results - Create a box plot where: - X-axis = NAICS2_NAME - Y-axis = SALARY_FROM, or SALARY_TO, or SALARY - Group/color = EMPLOYMENT_TYPE_NAME - Customize colors, fonts, and styles.\nExplanation: Write two sentences about what the graph reveals (e.g., median differences across industries and dispersion by employment type)."
  },
  {
    "objectID": "assignment03-juliovargas.html#plotly-template-example",
    "href": "assignment03-juliovargas.html#plotly-template-example",
    "title": "Assignment 03",
    "section": "plotly template example",
    "text": "plotly template example\n#| echo: true\nimport plotly.graph_objects as go\nimport plotly.io as pio\n\npio.templates[\"nike\"] = go.layout.Template(\n    # LAYOUT\n    layout = {\n        # Fonts\n        # Note - 'family' must be a single string, NOT a list or dict!\n        'title': {\n            'font': {'family': 'HelveticaNeue-CondensedBold, Helvetica, Sans-serif',\n                     'size': 30,\n                     'color': '#333'}\n        },\n        'font': {'family': 'Helvetica Neue, Helvetica, Sans-serif',\n                 'size': 16,\n                 'color': '#333'},\n\n        # Colorways\n        'colorway': ['#ec7424', '#a4adab'],\n        # Keep adding others as needed below\n        'hovermode': 'x unified'\n    },\n    # DATA\n    data = {\n        # Each graph object must be in a tuple or list for each trace\n        'bar': [go.Bar(\n            texttemplate = '%{value:$.2s}',\n            textposition = 'outside',\n            textfont = {'family': 'Helvetica Neue, Helvetica, Sans-serif',\n                        'size': 20,\n                        'color': '#FFFFFF'}\n        )]\n    }\n)"
  }
]